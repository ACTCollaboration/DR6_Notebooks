{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ACTCollaboration/DR6_Notebooks/blob/main/ACT_DR6_lensing_transfer_function.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating the ACT Lensing Transfer Function\n",
        "\n",
        "*Written by Joshua Kim and the ACT collaboration*\n",
        "\n",
        "---\n",
        "\n",
        "This notebook will demonstrate how we generate the lensing transfer function for the ACT Data Release 6 (DR6) analyses. In order to extract cosmological information from CMB lensing maps we compute the lensing power spectrum. Once we have this spectrum, it's important to correctly calibrate it in order to account for any biases. This calibration is done by testing our pipeline on simulations and then generating a multiplicative transfer function which is then used in conjunction with the biased spectrum in order to recover the \"true\" power spectrum.\n",
        "\n",
        "In order to compute this transfer function we rely on realistic simulations of the ACT lensing maps. For the actual analysis we use 400 simulations, however, due to the limitations of working in a notebook we have simplified the analysis by using only a handful of simulations. For anyone who wishes to recreate the full transfer function we suggest moving this code to a cluster and running it with the full suite of sims.\n",
        "\n",
        "\n",
        "The data for this release is publicly available on [Lambda](https://lambda.gsfc.nasa.gov/product/act/actadv_prod_table.html) and a full discussion of the ACT DR6 lensing analysis can be found in [Qu et al. (2023) ](https://arxiv.org/abs/2304.05202), [Madhavacheril et al. (2023)](https://arxiv.org/abs/2304.05203), [MacCrann et al. (2023)](https://arxiv.org/abs/2304.05196) and [Farren et al. (2023)](https://arxiv.org/abs/2309.05659).\n",
        "\n",
        "The pipeline presented below relies on a number of other packages including [`healpy`](https://healpy.readthedocs.io/en/latest/), [`pixell`](https://pixell.readthedocs.io/en/latest/) and [`NaMaster`](https://arxiv.org/abs/1809.09603) and we encourage users to refer to the relevant documentation as needed.\n",
        "\n",
        "For anyone who would like a bit more background in CMB analysis we recommend a few other resources from ACT at the end of this notebook."
      ],
      "metadata": {
        "id": "F1y6vWxNgvRM"
      },
      "id": "F1y6vWxNgvRM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run ONCE only"
      ],
      "metadata": {
        "id": "o3pczygM4TTE"
      },
      "id": "o3pczygM4TTE"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install() # expect a kernel restart"
      ],
      "metadata": {
        "id": "UzyJxFHq4EaT"
      },
      "id": "UzyJxFHq4EaT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A kernel restart is *expected* if the condacolab cell runs successfully. Proceed by testing the install with the next cell!"
      ],
      "metadata": {
        "id": "dwJhdBMSjArN"
      },
      "id": "dwJhdBMSjArN"
    },
    {
      "cell_type": "code",
      "source": [
        "import condacolab\n",
        "condacolab.check()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJMUgpFl885u",
        "outputId": "0b02e012-8d50-44a2-a1ed-a46c712ba207"
      },
      "id": "ZJMUgpFl885u",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ú®üç∞‚ú® Everything looks OK!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c546798",
      "metadata": {
        "id": "6c546798"
      },
      "source": [
        "# Data Products"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2c44bc7",
      "metadata": {
        "id": "b2c44bc7"
      },
      "source": [
        "We need the following:\n",
        "\n",
        "*   Some secondary mask (e.g. from a galaxy survey of choice)\n",
        "*   ACT DR6 lensing analysis mask\n",
        "*   Simulations of ACT DR6 lensing reconstructions\n",
        "*   Input lensing potentials used to create the simulations mentioned above\n",
        "\n",
        "\n",
        "The first two are easiest to use in `healpix` format (make sure they have the same `Nside` resolution!), but can be converted from `pixell` formats using the `pixell.reproject` module. The latter two are most commonly formatted as spherical harmonic transform coefficients, commonly known as `alms`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll start by downloading the neccesary data, this might take a bit of time.\n",
        "This specific example of the galaxy mask used here is discussed in [DES Collaboration (2021)](https://arxiv.org/abs/2107.04646)."
      ],
      "metadata": {
        "id": "iReAk_nD6qUB"
      },
      "id": "iReAk_nD6qUB"
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# sims\n",
        "!wget https://phy-act1.princeton.edu/public/data/dr6_lensing_v1/maps/baseline/simulations/kappa_alm_sim_act_dr6_lensing_v1_baseline_000{1..9}.fits\n",
        "!wget https://phy-act1.princeton.edu/public/data/dr6_lensing_v1/maps/baseline/simulations/kappa_alm_sim_act_dr6_lensing_v1_baseline_0010.fits\n",
        "!wget https://phy-act1.princeton.edu/public/data/dr6_lensing_v1/sim_inputs/kappa_alm/input_kappa_alm_sim_000{1..9}.fits\n",
        "!wget https://phy-act1.princeton.edu/public/data/dr6_lensing_v1/sim_inputs/kappa_alm/input_kappa_alm_sim_0010.fits\n",
        "\n",
        "# lensing masks\n",
        "!wget https://phy-act1.princeton.edu/public/data/dr6_lensing_v1/maps/baseline/mask_act_dr6_lensing_v1_healpix_nside_4096_baseline.fits\n",
        "\n",
        "# galaxy mask\n",
        "!wget https://desdr-server.ncsa.illinois.edu/despublic/y3a2_files/baosample/DESY3_LSSBAO_MASK_HPIX4096NEST.fits\n"
      ],
      "metadata": {
        "id": "kRRTRGAj5_fe"
      },
      "id": "kRRTRGAj5_fe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FILLER = \"#\"\n",
        "RECON_SIM_FORMAT = \"kappa_alm_sim_act_dr6_lensing_v1_baseline_####.fits\"\n",
        "INPUT_KAPPA_FORMAT = \"input_kappa_alm_sim_####.fits\""
      ],
      "metadata": {
        "id": "K8FQOhlihKOE"
      },
      "id": "K8FQOhlihKOE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "335c9633",
      "metadata": {
        "id": "335c9633"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d3aeaf9",
      "metadata": {
        "id": "8d3aeaf9"
      },
      "source": [
        "Requires:\n",
        "\n",
        "*   `numpy`\n",
        "*   `healpy`\n",
        "*   `pymaster`\n",
        "*   `pixell`\n",
        "\n",
        "This cell can take a few minutes to run as well."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install numpy healpy pixell pyfisher\n",
        "\n",
        "!mamba install -y -c conda-forge namaster"
      ],
      "metadata": {
        "id": "W_9AGYhbzhRG"
      },
      "id": "W_9AGYhbzhRG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a74a5a88",
      "metadata": {
        "id": "a74a5a88"
      },
      "outputs": [],
      "source": [
        "import healpy as hp\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pixell import enmap, reproject, lensing as plensing, curvedsky as cs\n",
        "\n",
        "import os, time\n",
        "\n",
        "import pymaster as nmt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d43a0453",
      "metadata": {
        "id": "d43a0453"
      },
      "source": [
        "# Constants"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6b17838",
      "metadata": {
        "id": "c6b17838"
      },
      "source": [
        "These constants set the ell range that will be analyzed, the size of the bin (`LperBin`) and the `NSIDE` of the healpix maps. There are two `LMAX` values here, `LMAX` refers to the maximum ell that the calculation will be performed up to and `LMAX_CUT` is the desired upper bound (more on this later!). Feel free to change these as needed!\n",
        "\n",
        "Note the number of bandpowers will be `(LMAX_CUT - LMIN) / LperBin`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f56bbc1",
      "metadata": {
        "id": "1f56bbc1"
      },
      "outputs": [],
      "source": [
        "LMIN = 40\n",
        "LMAX = 3000\n",
        "LMAX_CUT = 1000\n",
        "LperBin = 30\n",
        "NSIDE = 1024"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mask setup / manipulation\n",
        "\n",
        "Not necessary, but making our masks a bit easier to use for the sake of this tutorial."
      ],
      "metadata": {
        "id": "L0AgDktACyTK"
      },
      "id": "L0AgDktACyTK"
    },
    {
      "cell_type": "code",
      "source": [
        "# read in the masks...\n",
        "GALAXY_MASK = hp.read_map(\"DESY3_LSSBAO_MASK_HPIX4096NEST.fits\")\n",
        "LENSING_MASK = hp.read_map(\"mask_act_dr6_lensing_v1_healpix_nside_4096_baseline.fits\")\n",
        "# downgrade it to a more sensible resolution for our purposes...\n",
        "GALAXY_MASK = hp.ud_grade(GALAXY_MASK, NSIDE)\n",
        "LENSING_MASK = hp.ud_grade(LENSING_MASK, NSIDE)\n",
        "# and then make it binary for a simplified calculation.\n",
        "GALAXY_MASK[GALAXY_MASK < 0.3] = 0.\n",
        "GALAXY_MASK[GALAXY_MASK > 0.3] = 1.\n",
        "\n",
        "# build enmap versions of these masks for future usage\n",
        "# don't need these for running the rest of the notebook's cells!\n",
        "\n",
        "#shape, wcs = enmap.fullsky_geometry(res=np.deg2rad(1.0/60))\n",
        "#LENSING_MASK_ENMAP = reproject.healpix2map(LENSING_MASK, shape, wcs)\n",
        "#GALAXY_MASK_ENMAP = reproject.healpix2map(GALAXY_MASK, shape, wcs)\n",
        "\n",
        "# plot!\n",
        "hp.mollview(GALAXY_MASK)\n",
        "print(f\"fsky (gmask): {np.sum(GALAXY_MASK) / np.size(GALAXY_MASK) : 0.5f}\")\n",
        "hp.mollview(LENSING_MASK)\n",
        "print(f\"fsky (kmask): {np.sum(LENSING_MASK) / np.size(LENSING_MASK) : 0.5f}\")\n",
        "\n",
        "joint = GALAXY_MASK*LENSING_MASK\n",
        "print(f\"fsky (overlap): {np.sum(joint) / np.size(joint) : 0.5f}\")"
      ],
      "metadata": {
        "id": "Q5-ll5I2CGWP"
      },
      "id": "Q5-ll5I2CGWP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f29e377b",
      "metadata": {
        "id": "f29e377b"
      },
      "source": [
        "# Binning (NaMaster)\n",
        "\n",
        "We'll set up a few functions that will help us bin the spectra later on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b48d402",
      "metadata": {
        "id": "9b48d402"
      },
      "outputs": [],
      "source": [
        "# bin cls according to some scheme encoded in the coupling matrix\n",
        "def bin_spectra(cls, coupling_matrix_name):\n",
        "    cls_nmt = np.array([cls])\n",
        "    try:\n",
        "        wsp = nmt.NmtWorkspace()\n",
        "        wsp.read_from(coupling_matrix_name)\n",
        "        return wsp.decouple_cell(wsp.couple_cell(cls_nmt))[0]\n",
        "    except RuntimeError:\n",
        "        return None\n",
        "\n",
        "def make_bins(nside=NSIDE,LperBin=50,lmin=LMIN,lmax=LMAX):\n",
        "    ells    = np.arange(lmax,dtype='int32')\n",
        "    weights = 1. / LperBin * np.ones_like(ells)\n",
        "    weights[ells<lmin] = 0\n",
        "\n",
        "    # Now generate the bandpower indices, here by brute force.\n",
        "    # A -1 means that ell value is not included in any bandpower.\n",
        "    bpws = np.zeros_like(ells) - 1\n",
        "    ibin = 0\n",
        "    while LperBin*(ibin+1)+lmin<lmax:\n",
        "        bpws[LperBin*ibin+lmin:LperBin*(ibin+1)+lmin] = ibin\n",
        "        ibin += 1\n",
        "    # return Nmt binning instance\n",
        "    return nmt.NmtBin(nside,bpws=bpws,ells=ells,weights=weights)\n",
        "\n",
        "# return index for max bin index within a cutoff\n",
        "def max_bin(bin_edges, cutoff):\n",
        "    return np.argmax(np.nonzero(bin_edges < cutoff)[0]) + 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed68876b",
      "metadata": {
        "id": "ed68876b"
      },
      "source": [
        "# Transfer function computation (with NaMaster)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "581845ad",
      "metadata": {
        "id": "581845ad"
      },
      "source": [
        "The commonly defined transfer function, or $T(l)$, is computed here as the following:\n",
        "\n",
        "$$\n",
        "T(l) = \\dfrac{\\dfrac{1}{N} \\displaystyle\\sum_{\\text{sim } i}^{N} \\text{NmtBin}\\left(C^{\\hat{\\kappa} X}_{i, NMT} \\right)}{\\text{NmtBin}\\left(C^{\\kappa X}_{\\text{CAMB}}\\right)}\n",
        "$$\n",
        "\n",
        "where $X$ refers to either the input lensing convergence $\\kappa$ (used to lens the simulations) or a correlated galaxy field $g$ generated by populating a galaxy simulation so that it has the same auto and cross spectra as the provided theory (see `orphics.maps.generate_correlated_alm`).\n",
        "\n",
        "The denominator is computed according to cosmological parameters used to create the lensing simulations written in a CAMB .ini file to result in a theory spectrum that is binned by NaMaster (by coupling and then decoupling with a mode-coupling cell), and the numerator is computed as a mean over sims of a NaMaster-computed pseudo-Cl between the reconstructed convergence $\\hat{\\kappa}$ and $X$, ensuring that the binning of the denominator is done exactly the same way as the numerator.\n",
        "\n",
        "This is what we should *divide* our initial measurement by to correct the data products for any mode-coupling or fractional sky effects that we expect from the simulations.\n",
        "\n",
        "For this case, we will treat $X = \\kappa$."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c91eb8be",
      "metadata": {
        "id": "c91eb8be"
      },
      "source": [
        "## Numerator"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f2647a9",
      "metadata": {
        "id": "3f2647a9"
      },
      "source": [
        "We have to now iterate over sims and compute the mean pseudo-Cls with the masks passed into NaMaster. In our actual analysis this is done for 400 simulations, however, for the sake of this notebook we have limited the number of sims to save on both disk space and compute time.\n",
        "\n",
        "Here is the iterating function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c37c2a8",
      "metadata": {
        "id": "1c37c2a8"
      },
      "outputs": [],
      "source": [
        "START_INDEX = 1\n",
        "END_INDEX = 10 # inclusive\n",
        "\n",
        "!rm -rf nmt_transfer_function_coupling_matrix.fits\n",
        "COUPLING_MATRIX_NAME = \"nmt_transfer_function_coupling_matrix.fits\"\n",
        "\n",
        "# iterate a function \"fn\" over all sims with some indexing format\n",
        "# return dict d where d[idx] = fn(sims[idx], idx)\n",
        "# if is_healpix_map is set to False, assume the sims are alm files\n",
        "def iterate_over_kappa_sims(fn, sim_start=START_INDEX, sim_end=END_INDEX,\n",
        "                            common_format=\"sims_####.fits\", formatter=\"#\"):\n",
        "    data_dict = {}\n",
        "\n",
        "    for i in range(sim_start, sim_end+1):\n",
        "        # find appropriate file name for a given file index\n",
        "        ndigits = common_format.count(formatter)\n",
        "        filename = common_format.replace(formatter * ndigits, str(i).zfill(ndigits))\n",
        "\n",
        "        try:\n",
        "            print(f\"Running index #{str(i)}.\")\n",
        "            print(f\"Filename: {filename}\")\n",
        "            filedata = np.nan_to_num(hp.read_alm(filename)).astype(np.complex128)\n",
        "            print(\"Iterating...\")\n",
        "\n",
        "            fn(filedata, data_dict, i)\n",
        "            # for memory purposes\n",
        "            del filedata\n",
        "\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Could not find {filename}.\")\n",
        "            continue\n",
        "\n",
        "    return data_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abd3f448",
      "metadata": {
        "id": "abd3f448"
      },
      "source": [
        "And the helper function it needs to iterate:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1038e442",
      "metadata": {
        "id": "1038e442"
      },
      "outputs": [],
      "source": [
        "# now defining the \"fn\" to be iterated over in the definition above\n",
        "# \"kappa\" here refers to the reconstructed kappa sims\n",
        "def iterator_clkk(kappa, data_dict, idx):\n",
        "    # the index # \"idx\" also specifies the input potential filename\n",
        "    # assuming recon sim index # == input sim index #\n",
        "    input_kappa_filename = INPUT_KAPPA_FORMAT.replace(FILLER * INPUT_KAPPA_FORMAT.count(FILLER),\n",
        "                                                      str(idx).zfill(INPUT_KAPPA_FORMAT.count(FILLER)))\n",
        "    print(f\"Input kappa: {input_kappa_filename}\")\n",
        "\n",
        "    # the input alms are lensing convergence values stored as double complex values\n",
        "    input_kappa = np.nan_to_num(hp.read_alm(input_kappa_filename)).astype(np.complex128)\n",
        "\n",
        "    # run NaMaster!\n",
        "    kmask = LENSING_MASK\n",
        "    gmask = GALAXY_MASK\n",
        "\n",
        "    kmap = hp.alm2map(input_kappa, NSIDE)\n",
        "    khat_map = hp.alm2map(kappa, NSIDE)\n",
        "\n",
        "    # generate NaMaster binning object\n",
        "    b = make_bins(nside=NSIDE,LperBin=LperBin,lmin=LMIN,lmax=LMAX)\n",
        "\n",
        "    # The reconstructed lensing sims are made from pre-masked CMB temperature maps,\n",
        "    # so the quadratic estimator results in a lensing map effectively masked twice by the ACT mask\n",
        "    field_k_hat = nmt.NmtField(kmask**2, [khat_map], masked_on_input=True)\n",
        "    # No need to worry about the input lensing fields, since they are generated on the full sky\n",
        "    field_k = nmt.NmtField(gmask, [kmap], masked_on_input=False)\n",
        "\n",
        "    # only compute coupling matrix if not pre-computed / saved before\n",
        "    w = nmt.NmtWorkspace()\n",
        "    if os.path.isfile(COUPLING_MATRIX_NAME):\n",
        "        print(\"Reading coupling matrix from disk.\")\n",
        "        w.read_from(COUPLING_MATRIX_NAME)\n",
        "    else:\n",
        "        w.compute_coupling_matrix(field_k, field_k_hat, b)\n",
        "        print(\"Writing coupling matrix to disk.\")\n",
        "        w.write_to(COUPLING_MATRIX_NAME)\n",
        "\n",
        "    # use coupling matrix to generate pseudo-cls\n",
        "    clkk = w.decouple_cell(nmt.compute_coupled_cell(field_k, field_k_hat))[0]\n",
        "    nmtells = b.get_effective_ells()\n",
        "\n",
        "    # only run to desired lmax cut\n",
        "    data_dict[idx] = clkk[:max_bin(nmtells, LMAX_CUT)]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "557e625e",
      "metadata": {
        "id": "557e625e"
      },
      "source": [
        "Now we iterate over the desired number of sims (expect this cell to take a while, of O(30 min). It can take O(hours) for multiple hundreds of sims using much more RAM than this Colab environment offers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30edaa1b",
      "metadata": {
        "id": "30edaa1b"
      },
      "outputs": [],
      "source": [
        "time1 = time.time()\n",
        "clkk_data = iterate_over_kappa_sims(iterator_clkk, sim_start=START_INDEX, sim_end=END_INDEX,\n",
        "                                    common_format=RECON_SIM_FORMAT, formatter=FILLER)\n",
        "print(\"--\")\n",
        "print(f\"Time elapsed: {time.time()-time1:0.5f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be0ecaaa",
      "metadata": {
        "id": "be0ecaaa"
      },
      "source": [
        "## Denominator"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b31a4fab",
      "metadata": {
        "id": "b31a4fab"
      },
      "source": [
        "The denominator is simply the ACT DR6 lensing auto-spectrum theory prediction binned with `NaMaster`. Both the numerator and denominator will be binned up to a much higher ell (`LMAX`) than the desired limit (`LMAX_CUT`) to prevent power leakage at the smallest considered scales, and then cut at that limiting bin number after all binning is done.\n",
        "\n",
        "For this purpose, we will use a provided theory prediction of the lensing auto-spectrum instead of computing one ourselves."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/ACTCollaboration/actsims/master/data/cosmo2017_10K_acc3_lenspotentialCls.dat"
      ],
      "metadata": {
        "id": "QlAkbW-4g7eJ"
      },
      "id": "QlAkbW-4g7eJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a9b1836",
      "metadata": {
        "id": "8a9b1836"
      },
      "outputs": [],
      "source": [
        "ells, dr6_lensing_clkk = np.loadtxt(\"cosmo2017_10K_acc3_lenspotentialCls.dat\", usecols=[0,5], unpack=True)\n",
        "clkk_theory = dr6_lensing_clkk[ells < 3*NSIDE] * np.pi / 2\n",
        "\n",
        "# usually monopole and dipole of lensing auto-spectrum is set to zero\n",
        "# if included at all, but needs to be included for binning\n",
        "clkk_theory = np.append(np.array([0,0]), clkk_theory)\n",
        "\n",
        "# Now bin with NaMaster. We will reuse \"b\"!\n",
        "b = make_bins(nside=NSIDE,LperBin=LperBin,lmin=LMIN,lmax=LMAX)\n",
        "\n",
        "# cut to LMAX_CUT\n",
        "clkk_theory_binned = bin_spectra(clkk_theory,\n",
        "                                 COUPLING_MATRIX_NAME)[:max_bin(b.get_effective_ells(), LMAX_CUT)]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "357bb21a",
      "metadata": {
        "id": "357bb21a"
      },
      "source": [
        "Compute the mean of the sim-based spectrum computation over the sims for the transfer function as well as the scatter via covariance matrix from the sims to estimate error bars for our transfer function measurement:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1775a376",
      "metadata": {
        "id": "1775a376"
      },
      "outputs": [],
      "source": [
        "clkk_sims = np.array([clkk_data[k] for k in clkk_data.keys()])\n",
        "clkk_mean_sims = np.mean(clkk_sims, axis=0)\n",
        "\n",
        "# computing error bars (on the mean) from sims covariance\n",
        "errs = 1/np.sqrt(END_INDEX - START_INDEX + 1) * np.sqrt(np.std(clkk_sims / clkk_theory_binned, axis=0))\n",
        "xfn = clkk_mean_sims / clkk_theory_binned\n",
        "\n",
        "# Write to disk\n",
        "ells = b.get_effective_ells()\n",
        "ells = ells[:max_bin(ells, LMAX_CUT)]\n",
        "np.savetxt(\"act-dr6-transfer-function.txt\", np.column_stack((ells, xfn, errs)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transfer function calculation (without NaMaster)"
      ],
      "metadata": {
        "id": "qinjXm_mMHDC"
      },
      "id": "qinjXm_mMHDC"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The commonly defined transfer function, or $T(l)$, is computed here as the following:\n",
        "\n",
        "$$\n",
        "T(l) = \\dfrac{\\dfrac{1}{N} \\displaystyle\\sum_{\\text{sim } i}^{N} C^{\\hat{\\kappa} X}_{i}}{C^{\\kappa X}_{\\text{CAMB}}}\n",
        "$$\n",
        "\n",
        "where $X$ refers to either the input lensing convergence $\\kappa$ (used to lens the simulations) or a correlated galaxy field $g$ generated by populating a galaxy simulation so that it has the same auto and cross spectra as the provided theory (see `orphics.maps.generate_correlated_alm`). Again, we will treat $X = \\kappa$.\n",
        "\n",
        "The denominator is computed in the exact same way as above, but we no longer use NaMaster to bin the spectra in both the denominator and numerator. To compute the numerator, we first compute the full-sky cross spectrum between the sets of alms:\n",
        "\n",
        "$$\n",
        "C^{XY}_l = \\dfrac{1}{2l+1} \\displaystyle\\sum_{m = -l}^l A_{lm} B^*_{lm}\n",
        "$$\n",
        "\n",
        "and then utilize an approximation using powers of the $w$-factor to account for the sky fraction excluded by the powers of the analysis mask.\n",
        "\n",
        "We will not compute this version in the notebook as a $w$-factor that uses multiple powers of different analysis masks is not trivial to compute. However, here are the appropriate functions to compute this $w$-factor for a given `pixell` enmap-formatted mask:"
      ],
      "metadata": {
        "id": "Ywav7bm-MKsP"
      },
      "id": "Ywav7bm-MKsP"
    },
    {
      "cell_type": "code",
      "source": [
        "def wfactor(n,mask,sht=True,pmap=None,equal_area=False):\n",
        "    \"\"\"\n",
        "    Approximate correction to an n-point function for the loss of power\n",
        "    due to the application of a mask.\n",
        "\n",
        "    from https://github.com/msyriac/orphics/blob/master/orphics/maps.py\n",
        "    \"\"\"\n",
        "    assert mask.ndim==1 or mask.ndim==2\n",
        "    if pmap is None:\n",
        "        if equal_area:\n",
        "            npix = mask.size\n",
        "            pmap = 4*np.pi / npix if sht else enmap.area(mask.shape,mask.wcs) / npix\n",
        "        else:\n",
        "            pmap = enmap.pixsizemap(mask.shape,mask.wcs)\n",
        "    return np.sum((mask**n)*pmap) /np.pi / 4. if sht else np.sum((mask**n)*pmap) / np.sum(pmap)\n",
        "\n",
        "def w_n(mask,n=3):\n",
        "    \"\"\"compute the wfactor for an n-point function\"\"\"\n",
        "    pmap = enmap.pixsizemap(mask.shape,mask.wcs)\n",
        "    return wfactor(n,mask,sht=True,pmap=pmap)"
      ],
      "metadata": {
        "id": "zDpWw3MKTfFv"
      },
      "id": "zDpWw3MKTfFv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "4f7806be",
      "metadata": {
        "id": "4f7806be"
      },
      "source": [
        "# T(l) results and plots"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's do a quick visualization of the numerator and denominator to see their agreement:"
      ],
      "metadata": {
        "id": "FUhSgTClyBe_"
      },
      "id": "FUhSgTClyBe_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ec029aa",
      "metadata": {
        "id": "3ec029aa"
      },
      "outputs": [],
      "source": [
        "# cut x-axis ells to LMAX_CUT\n",
        "ells = b.get_effective_ells()\n",
        "ells = ells[:max_bin(ells, LMAX_CUT)]\n",
        "\n",
        "plt.figure(figsize=(12,9))\n",
        "plt.plot(ells, clkk_theory_binned, label=\"denominator (NaMaster)\")\n",
        "plt.plot(ells, clkk_mean_sims, label=\"numerator (NaMaster)\")\n",
        "plt.xlabel(r\"$L$\", size=24)\n",
        "plt.ylabel(r\"$C_L$\", size=24)\n",
        "plt.legend(prop={'size': 16})\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we can only show 10 cross-correlations of sims, the covariance is very likely to be unconverged and the error bars will blow up; the error on the mean is expected to be smaller and more sensible once a full suite of simulations that have at least $N_{sims} > N_{bandpowers}$ simulations are run."
      ],
      "metadata": {
        "id": "9TIpDk4evkC3"
      },
      "id": "9TIpDk4evkC3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "232a1d24",
      "metadata": {
        "id": "232a1d24"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,9))\n",
        "plt.title(f\"Transfer function from ACT DR6 lensing sims #{START_INDEX} ~ #{END_INDEX}\", size=20)\n",
        "plt.errorbar(ells, xfn, errs, fmt='-o', label=\"NaMaster\")\n",
        "plt.plot(ells, ells * 0. + 1., '--', color='grey')\n",
        "plt.legend(prop={'size': 16})\n",
        "plt.xlabel(r\"$L$\", size=24)\n",
        "plt.ylabel(r\"$\\bar{C}_L^{\\hat{\\kappa} \\kappa} / C_{L,th}^{\\kappa \\kappa}$\", size=24)\n",
        "plt.savefig(\"act-dr6-transfer-function-plot.png\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It appears as this transfer function is on the order of a few percent and is quite noisy and fluctuating around 1 with no obviously explicit scale dependence. Once again, it is highly recommended to compute the transfer function with more simulations to gain more confidence in the scatter, and once computed, to divide a computed cross-correlation measurement by the bandpowers of this transfer function."
      ],
      "metadata": {
        "id": "Y6bO5IWjyOnh"
      },
      "id": "Y6bO5IWjyOnh"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Related resources:\n",
        "\n",
        "For more examples of how to use ACT data consider using:\n",
        "- The DR6 Lensing notebooks available on github\n",
        "- The DR4 and DR5 ACT notebooks available on [github](https://github.com/ACTCollaboration)\n",
        "- The `pixell` notebooks which are available on the [`pixell` repo](https://github.com/simonsobs/pixell/tree/master) and describe how to work with maps from ACT"
      ],
      "metadata": {
        "id": "NBUKFhV2AlTc"
      },
      "id": "NBUKFhV2AlTc"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:.conda-myenv] *",
      "language": "python",
      "name": "conda-env-.conda-myenv-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
